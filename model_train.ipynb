{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61d7466-338b-424b-8e9d-61699f9e3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, os, cv2, PIL, torch\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torchsummary as ts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1305a310-8b3a-4b1b-ac9b-27ae64611f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c12f7a-55f3-4707-aca4-6d98b55d3f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 43\n",
    "cur_path = os.getcwd()\n",
    "\n",
    "# Retrieving the images and their labels\n",
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path, 'Train', str(i))\n",
    "    images = os.listdir(path)\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(os.path.join(path, a))\n",
    "            image = image.resize((32, 32))\n",
    "            image = np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            print(\"Error loading image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08feca02-7ae2-4d0c-b04c-1bda0e864f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 32, 32, 3) (39209,)\n",
      "(31367, 32, 32, 3) (7842, 32, 32, 3) (31367,) (7842,)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(data.shape, labels.shape)\n",
    "\n",
    "# Splitting training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=100)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ffd9b2a-69c8-4f7c-8d04-6771b0045678",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomGrayscale(object):\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            img = transforms.functional.rgb_to_grayscale(img, num_output_channels=3)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbdf50b9-bc92-4dd2-be9b-c4ecc454064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    RandomGrayscale(p=0.2),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train, transform=transform)\n",
    "test_dataset = CustomDataset(X_test, y_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e6c9b2-0fd1-41cc-a8e8-0406b483dd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             208\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "              ReLU-3           [-1, 16, 32, 32]               0\n",
      "         MaxPool2d-4           [-1, 16, 16, 16]               0\n",
      "            Conv2d-5           [-1, 32, 16, 16]           2,080\n",
      "       BatchNorm2d-6           [-1, 32, 16, 16]              64\n",
      "              ReLU-7           [-1, 32, 16, 16]               0\n",
      "         MaxPool2d-8             [-1, 32, 8, 8]               0\n",
      "            Conv2d-9             [-1, 64, 8, 8]           8,256\n",
      "      BatchNorm2d-10             [-1, 64, 8, 8]             128\n",
      "             ReLU-11             [-1, 64, 8, 8]               0\n",
      "        MaxPool2d-12             [-1, 64, 4, 4]               0\n",
      "          Flatten-13                 [-1, 1024]               0\n",
      "           Linear-14                  [-1, 256]         262,400\n",
      "             ReLU-15                  [-1, 256]               0\n",
      "           Linear-16                   [-1, 43]          11,051\n",
      "================================================================\n",
      "Total params: 284,219\n",
      "Trainable params: 284,219\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.72\n",
      "Params size (MB): 1.08\n",
      "Estimated Total Size (MB): 1.82\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\pt\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Convolution.cpp:1032.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "                        # 1st convolutional network Layers\n",
    "                        nn.Conv2d(3,16,(2,2),(1,1),'same'),   # Convolution\n",
    "                        nn.BatchNorm2d(16),                   # Normalization \n",
    "                        nn.ReLU(True),                       # Activation\n",
    "                        nn.MaxPool2d((2,2)),                 # Pooling\n",
    "    \n",
    "                        # 2nd convolutional network Layers\n",
    "                        nn.Conv2d(16,32,(2,2),(1,1),'same'),  # Convolution\n",
    "                        nn.BatchNorm2d(32),                  # Normalization \n",
    "                        nn.ReLU(True),                       # Activation\n",
    "                        nn.MaxPool2d((2,2)),                 # Pooling\n",
    "    \n",
    "                        # 3rd convolutional network Layers\n",
    "                        nn.Conv2d(32,64,(2,2),(1,1),'same'), # Convolution\n",
    "                        nn.BatchNorm2d(64),                  # Normalization \n",
    "                        nn.ReLU(True),                       # Activation\n",
    "                        nn.MaxPool2d((2,2)),                 # Pooling\n",
    "\n",
    "                        # Flatten Data\n",
    "                        nn.Flatten(),                        # Flatten\n",
    "    \n",
    "                        # feed forward Layers\n",
    "                        nn.Linear(1024,256),                  # Linear \n",
    "                        nn.ReLU(True),                       # Activation\n",
    "                        nn.Linear(256,43)                    # Linear \n",
    "                    )\n",
    "\n",
    "# Send model to Cuda Memory\n",
    "model = model.to(torch.device('cuda'),non_blocking=True)\n",
    "# For Model Summary\n",
    "ts.summary(model,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b5c3135-9b24-40f6-af7d-7d755a00edfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 Training: 100%|██████████| 123/123 [00:07<00:00, 16.71it/s, loss=2.21]\n",
      "Epoch 1/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 16.94it/s, accuracy=64.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 64.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 Training: 100%|██████████| 123/123 [00:08<00:00, 14.64it/s, loss=0.8]  \n",
      "Epoch 2/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 18.38it/s, accuracy=87.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 87.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 Training: 100%|██████████| 123/123 [00:08<00:00, 14.94it/s, loss=0.379]\n",
      "Epoch 3/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 17.27it/s, accuracy=93.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 93.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 Training: 100%|██████████| 123/123 [00:08<00:00, 14.93it/s, loss=0.231]\n",
      "Epoch 4/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 16.27it/s, accuracy=94.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 94.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 Training: 100%|██████████| 123/123 [00:07<00:00, 15.80it/s, loss=0.164]\n",
      "Epoch 5/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 16.83it/s, accuracy=96.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 96.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 Training: 100%|██████████| 123/123 [00:08<00:00, 14.69it/s, loss=0.117]\n",
      "Epoch 6/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 19.16it/s, accuracy=97.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 97.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 Training: 100%|██████████| 123/123 [00:08<00:00, 15.03it/s, loss=0.0899]\n",
      "Epoch 7/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 17.13it/s, accuracy=96.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 96.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 Training: 100%|██████████| 123/123 [00:08<00:00, 15.07it/s, loss=0.0727]\n",
      "Epoch 8/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 17.71it/s, accuracy=97.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 97.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 Training: 100%|██████████| 123/123 [00:08<00:00, 15.04it/s, loss=0.0587]\n",
      "Epoch 9/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 17.05it/s, accuracy=97.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 97.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 Training: 100%|██████████| 123/123 [00:08<00:00, 14.98it/s, loss=0.0477]\n",
      "Epoch 10/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 16.68it/s, accuracy=98]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 98.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 Training: 100%|██████████| 123/123 [00:08<00:00, 14.86it/s, loss=0.0392]\n",
      "Epoch 11/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 16.51it/s, accuracy=98.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 98.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 Training: 100%|██████████| 123/123 [00:08<00:00, 14.70it/s, loss=0.0319]\n",
      "Epoch 12/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 16.11it/s, accuracy=98.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 98.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 Training: 100%|██████████| 123/123 [00:08<00:00, 15.20it/s, loss=0.0278]\n",
      "Epoch 13/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 16.60it/s, accuracy=98]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 98.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 Training: 100%|██████████| 123/123 [00:08<00:00, 14.50it/s, loss=0.0255]\n",
      "Epoch 14/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 15.92it/s, accuracy=98.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 98.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 Training: 100%|██████████| 123/123 [00:07<00:00, 16.06it/s, loss=0.0227]\n",
      "Epoch 15/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 20.29it/s, accuracy=98.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 98.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 Training: 100%|██████████| 123/123 [00:07<00:00, 16.83it/s, loss=0.017] \n",
      "Epoch 16/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 16.44it/s, accuracy=97.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 97.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 Training: 100%|██████████| 123/123 [00:08<00:00, 15.00it/s, loss=0.0151]\n",
      "Epoch 17/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 16.72it/s, accuracy=98.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 98.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 Training: 100%|██████████| 123/123 [00:08<00:00, 14.80it/s, loss=0.0145]\n",
      "Epoch 18/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 16.81it/s, accuracy=98.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 98.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 Training: 100%|██████████| 123/123 [00:08<00:00, 14.70it/s, loss=0.0117]\n",
      "Epoch 19/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 17.91it/s, accuracy=98.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 98.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 Training: 100%|██████████| 123/123 [00:08<00:00, 14.70it/s, loss=0.0118]\n",
      "Epoch 20/20 Validation: 100%|██████████| 31/31 [00:01<00:00, 18.09it/s, accuracy=98.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 7842 test images: 98.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Оберните train_loader с tqdm для визуализации прогресса\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Training\")\n",
    "    for i, (images, labels) in enumerate(pbar):\n",
    "        # Transfer to GPU\n",
    "        images, labels = images.to(torch.device('cuda')), labels.to(torch.device('cuda'))\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': running_loss / (i + 1)})\n",
    "    \n",
    "    # Validation of the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_pbar = tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Validation\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_pbar:\n",
    "            images, labels = images.to(torch.device('cuda')), labels.to(torch.device('cuda'))\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            val_pbar.set_postfix({'accuracy': 100 * correct / total})\n",
    "\n",
    "    print(f'Accuracy of the model on the {len(test_dataset)} test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f31e3c9-74fd-4695-a017-e6e9deebab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"best_model_epoch_{777}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4787abd9-26d6-46fc-a353-77463da34665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptkernel",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
